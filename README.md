KNOW THEM - application the visually challenged
The aim of this project is to empower visually impaired individuals by developing an innovative, multisensory technology solution that enhances their ability to 
understand and respond to the emotions of others during social interactions. Through the integration of cutting-edge technology and thoughtful 
design, the project aims to contribute to the broader goal of building a more empathetic and inclusive society for the visually impaired community.

Main Python Packages that are used: 
Numpy 
opencv-python
keras
tensorflow
Till now there are 3 modules introduced that includes,

###Facial Emotion Detection 
Data set used: https://www.kaggle.com/datasets/msambare/fer2013
Emotions that are classified: "Angry", "Disgusted", "Fearful", "Happy", "Neutral",  "Sad", "Surprised"

Implemented a real-time face detection and recognition module using a deep learning
based approach like CNN (Convolutional Neural Networks) or Haar Cascade 
Classifier. 

###Indian Currency Detection

Integrated a currency detection module capable of recognizing different 
denominations of Indian banknotes. 

###Object Detection
The object detetction module is implemented using YOLO v5 algorithm from https://github.com/ultralytics/ultralytics.
Typically, YOLOv5 is pretrained on the COCO (Common Objects in Context) dataset, which includes 80 different object classes.

